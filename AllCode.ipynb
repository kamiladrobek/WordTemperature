{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Data Exploration and HeatMaps\n"],"metadata":{"id":"Cx93p6P8y-Ht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","file = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"DtbYKy_sgqoY","executionInfo":{"status":"ok","timestamp":1689709233231,"user_tz":-120,"elapsed":109991,"user":{"displayName":"Tarik Anouar","userId":"03020327153949348021"}},"outputId":"ce9dbede-947f-482d-df9c-5da927f49a5d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-dbdf56a0-5ac6-4ed2-b7de-9c738527b183\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-dbdf56a0-5ac6-4ed2-b7de-9c738527b183\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving hadcrut-surface-temperature-anomaly.csv to hadcrut-surface-temperature-anomaly.csv\n","Saving owid-co2-data.csv to owid-co2-data.csv\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sL_3Z3njR-qC"},"outputs":[],"source":["%matplotlib inline\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import numpy as np\n","import seaborn as sns\n","from matplotlib.cm import ScalarMappable\n","from matplotlib.colors import LinearSegmentedColormap, Normalize\n","\n","#from google.colab import files\n","#file = files.upload()\n","\n","#from google.colab import drive\n","#drive.flush_and_unmount()\n","\n","#kamilas files1\n","\n","import pandas as pd\n","df1 = pd.read_csv('/content/owid-co2-data.csv')[['country', 'iso_code','year','gdp',\"population\", \"co2\", \"coal_co2\", \"gas_co2\", \"methane\", \"nitrous_oxide\", \"total_ghg\", \"oil_co2\"]]\n","df2 = pd.read_csv('/content/hadcrut-surface-temperature-anomaly.csv')\n","\n","merged_df = pd.merge(df1, df2, left_index=True, right_index=True)\n","merged_df = pd.concat([df1, df2], axis=0)\n","\n","description = merged_df.describe()\n","print(description)\n","import matplotlib.pyplot as plt\n","\n","description = merged_df.describe()\n","\n","# Create a table\n","from tabulate import tabulate\n","\n","description = merged_df.describe().transpose()\n","\n","# Convert the statistical values to a table\n","table = tabulate(description, headers='keys', tablefmt='psql')\n","\n","# Print the table\n","print(table)\n","# lib import\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","df1 = pd.read_csv('/content/owid-co2-data.csv')[['country', 'iso_code','year','gdp',\"population\", \"co2\", \"coal_co2\", \"gas_co2\", \"methane\", \"nitrous_oxide\", \"total_ghg\", \"oil_co2\"]]\n","df2 = pd.read_csv('/content/hadcrut-surface-temperature-anomaly.csv')\n","\n","merged_df = pd.merge(df1, df2, left_index=True, right_index=True)\n","merged_df = pd.concat([df1, df2], axis=0)\n","\n","# delete the nan values\n","clean_df = merged_df.dropna() #<-- You have too many NA so the shape the dataframe is equal to 0, clean_df is empty\n","\n","# select the necessary inputs to focus on features can affect the global warming\n","light_df = clean_df\n","\n","# use describe method to have basic stats values\n","light_df.describe()\n","\n","#new\n","df=pd.read_csv('hadcrut-surface-temperature-anomaly.csv')\n","df=df.rename(columns={\"Entity\": \"country\", \"Year\" : \"year\"})\n","\n","df_co2 = pd.read_csv('owid-co2-data.csv')\n","\n","df_merge = df.merge(df_co2, on=['country', 'year'], how='left')\n","\n","df_merge.corr().style.background_gradient(cmap='coolwarm').set_precision(3)"]},{"cell_type":"code","source":["#reading the temperature anomaly data file\n","temp_anomal = pd.read_csv('/content/hadcrut-surface-temperature-anomaly.csv')\n","temp_anomal = temp_anomal.sort_values('Year') #we sort by years in the dataframe\n","\n","#reading the CO2 data file\n","co2_data = pd.read_csv('/content/owid-co2-data.csv')\n","\n","#displaying basic info about temp_anomal database\n","print(temp_anomal.info())\n","print(\"The shape of the temperature anomaly dataset is:\", temp_anomal.shape)\n","#we see how manny missing values there are for each column\n","print(temp_anomal.isna().sum())\n","print(\"The dataset contains\",temp_anomal.isna().sum().sum(), \"NaN values, all for country ISO Code.\")\n","#We calculate how many countries are listed in the dataset\n","print('The dataset contains information about', temp_anomal['Entity'].nunique(), 'countries.')\n","#We calculate how many data entries there are for each country\n","print('The data for each country is available for the following number of years:', temp_anomal['Entity'].value_counts())\n","#We see that the number of years with temperature anomaly data is not the same for each country\n","print('There is a distribution of entries for various countries. \\\n","The values vary from information about 168 years of temperature anomalies to 64 years. However, the earlier data are available and are important in the project.')\n","\n","#displaying basic info about co2_data database\n","print(co2_data.info())\n","print(\"The shape of the CO2 dataset is:\", co2_data.shape)\n","#we see how manny missing values there are for each column\n","print(co2_data.isna().sum())\n","#We calculate how many countries are listed in the dataset, countries but also dependent states have ISO code\n","print('The dataset contains information about', co2_data['iso_code'].nunique(), 'countries and states.')"],"metadata":{"id":"3Uzuidd0SHcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#function for plotting 5 countries with the highest temperature anomalies\n","def countries_temp_anomaly(year):\n","    #we choose one specific year for the data, eg. 2017\n","    year_data = temp_anomal[temp_anomal['Year'] == year]\n","    used_data = year_data[['Entity', 'Surface temperature anomaly']]\n","    sorted_data = used_data.sort_values('Surface temperature anomaly', ascending=False).reset_index(drop=True)\n","    chart_data = sorted_data.iloc[:5]\n","\n","    print(chart_data)\n","    # create bar chart\n","    plt.bar(chart_data['Entity'], chart_data['Surface temperature anomaly'],\n","            color=['#f6d2a9','#f5b78e','#f19c7c','#ea8171','#dd686c'])\n","    plt.title('Countries with the highest temperature anomaly in deg C (2017)')\n","    plt.xticks(fontsize=8)\n","    plt.show()\n","\n","#function for plotting 5 countries with the highest CO2 emissions\n","def co2_emissions(year):\n","    year_data = co2_data[co2_data['year'] == year]\n","    # we use isna to remove the separate the countries and aggregated records for areas (eg. Asia)\n","    # only countries and dependent states have iso code\n","    country_data = year_data[pd.notna(year_data['iso_code'])]\n","    used_data = country_data[['country', 'co2']]\n","    sorted_data = used_data.sort_values('co2', ascending=False).reset_index(drop=True)\n","    chart_data = sorted_data.iloc[:5]\n","    print(chart_data)\n","    # create bar chart\n","    plt.bar(chart_data['country'], chart_data['co2'],\n","            color=[\"#115f9a\", \"#1984c5\", \"#22a7f0\", \"#48b5c4\", \"#76c68f\"])\n","    plt.title('Countries with the highest CO2 emissions in million tons (2021)')\n","    plt.xticks(fontsize=8)\n","    plt.show()\n","\n","\n","#function for plotting 7 countries with the highest share to the world CO2 emissions\n","def countries_share_piechart(year):\n","    year_data = co2_data[co2_data['year'] == year]\n","    # we use isna to remove the separate the countries and aggregated records for areas (eg. Asia)\n","    # only countries have iso code\n","    country_data = year_data[pd.notna(year_data['iso_code'])]\n","    used_data = country_data[['country', 'share_global_co2']]\n","    sorted_data = used_data.sort_values('share_global_co2', ascending=False).reset_index(drop=True)\n","    chart_data = sorted_data.iloc[:7]\n","    other_share = sorted_data.loc[7:, 'share_global_co2'].sum()\n","    chart_data.loc[7] = (\"Other\", other_share)\n","    plt.title('Global share to the $\\mathdefault{CO_2}$ emissions', pad=32)\n","    print(chart_data)\n","\n","\n","    colors = sns.color_palette(\"Paired\")\n","    #labels = chart_data[chart_data['country']]\n","    # create pie chart\n","    plt.pie(chart_data['share_global_co2'], labels= chart_data['country'], colors=colors, autopct='%.0f%%',\n","        explode = [0.1, 0, 0, 0, 0, 0, 0, 0],\n","        pctdistance = 0.9, labeldistance = 1.2, radius=1.3)\n","\n","    plt.show()\n","\n","\n","#function for plotting 5 countries with the highest CO2 emissions\n","def country_co2_emission(country):\n","    country_data = co2_data[co2_data['country'] == country]\n","    x = country_data['year']\n","    y1 = country_data['population']\n","    y2 = country_data['co2']\n","    y3 = country_data['co2_per_capita']\n","\n","    fig, ax = plt.subplots()\n","    fig.subplots_adjust(right=0.75)\n","\n","    twin1 = ax.twinx()\n","    twin2 = ax.twinx()\n","\n","    # Offset the right spine of twin2.  The ticks and label have already been\n","    # placed on the right by twinx above.\n","    twin2.spines.right.set_position((\"axes\", 1.2))\n","\n","    p1, = ax.plot(x, y1, \"b-\", label = \"Population\")\n","    p2, = twin1.plot(x, y2, \"r-\", label=\"$\\mathdefault{CO_2}$\")\n","    p3, = twin2.plot(x, y3, \"g-\", label=\"$\\mathdefault{CO_2}$ per capita\")\n","\n","\n","    ax.set_xlabel(\"Year\")\n","    ax.set_ylabel(\"Population\")\n","    twin1.set_ylabel(\"$\\mathdefault{CO_2}$ [million tonnes]\")\n","    twin2.set_ylabel(\"$\\mathdefault{CO_2}$ per capita [tons pp]\")\n","\n","    ax.yaxis.label.set_color(p1.get_color())\n","    twin1.yaxis.label.set_color(p2.get_color())\n","    twin2.yaxis.label.set_color(p3.get_color())\n","\n","    tkw = dict(size=4, width=1.5)\n","    ax.tick_params(axis='y', colors=p1.get_color(), **tkw)\n","    twin1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n","    twin2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n","    ax.tick_params(axis='x', **tkw)\n","\n","    ax.legend(handles=[p1, p2, p3])\n","    plt.title(country +' $\\mathdefault{CO_2}$ emissions')\n","    plt.show()\n","\n","#function for plotting what is the countries share in the temperature change\n","def share_temp(year):\n","    year_data = co2_data[co2_data['year'] == year]\n","    # we use isna to remove the separate the countries and aggregated records for areas (eg. Asia)\n","    # only countries and dependent states have iso code\n","    country_data = year_data[pd.notna(year_data['iso_code'])]\n","    used_data = country_data[['country', 'share_of_temperature_change_from_ghg']]\n","    sorted_data = used_data.sort_values('share_of_temperature_change_from_ghg', ascending=False).reset_index(drop=True)\n","    chart_data = sorted_data.iloc[:7]\n","    other_share = sorted_data.loc[7:, 'share_of_temperature_change_from_ghg'].sum()\n","    chart_data.loc[7] = (\"Other\", other_share)\n","    print(chart_data)\n","    # create bar chart\n","    plt.bar(chart_data['country'], chart_data['share_of_temperature_change_from_ghg'],\n","            color=['#1D5B79', '#468B97', '#EF6262', '#F3AA60', '#1A5D1A', '#A84448', '#539165', '#3F497F'])\n","    plt.title('Share of contribution to global warming [in %]')\n","    plt.xticks(fontsize=8)\n","    plt.show()\n","\n","\n","#function for plotting the animated map for countries temperature anomalies\n","def animated_temp_map():\n","    fig = px.choropleth(temp_anomal, locations=\"Code\",\n","                        color=\"Surface temperature anomaly\", # temp anomally per country\n","                        hover_name=\"Entity\", # column to add to hover information\n","                        animation_frame='Year',\n","                        range_color=(-3, max(temp_anomal['Surface temperature anomaly'])),\n","                        color_continuous_scale=px.colors.sequential.Plasma)\n","\n","    fig.update_coloraxes(colorbar_ticksuffix ='  deg C') #we add suffix to the temp anomaly in the colorbar\n","    fig.update_layout(\n","        title_text='Surface temperature anomaly',\n","        geo=dict(\n","            showframe=False,\n","            showcoastlines=False,\n","            projection_type='equirectangular'\n","        ),\n","        annotations = [dict(\n","            x=0.55,\n","            y=0.2,\n","            xref='paper',\n","            yref='paper',\n","            text='Source: <a href=\"https://ourworldindata.org/grapher/hadcrut-surface-temperature-anomaly\">\\\n","                Our World In Data</a>',\n","            showarrow = False\n","        )]\n","    )\n","\n","    fig.show()\n","\n","\n","#function for plotting the map for countries temperature anomalies for a specific year\n","def yearly_temp_map(year):\n","    fig = px.choropleth(temp_anomal[temp_anomal['Year']==year], locations=\"Code\", #we plot data for the year (eg. 2017)\n","                        color=\"Surface temperature anomaly\", # temp anomaly per country\n","                        hover_name=\"Entity\", # column to add to hover information\n","                        color_continuous_scale=px.colors.sequential.Plasma #colorbar style\n","                        )\n","\n","    fig.update_coloraxes(colorbar_ticksuffix ='  deg C') #we add suffix to the temp anomaly in the colorbar\n","    fig.update_layout(\n","        title_text='Surface temperature anomaly, 2017',\n","        geo=dict(\n","            showframe=False,\n","            showcoastlines=False,\n","            projection_type='equirectangular'\n","        ),\n","        annotations = [dict(\n","            x=0.55,\n","            y=0.2,\n","            xref='paper',\n","            yref='paper',\n","            text='Source: <a href=\"https://ourworldindata.org/grapher/hadcrut-surface-temperature-anomaly\">\\\n","                Our World In Data</a>',\n","            showarrow = False\n","        )]\n","    )\n","    fig.show()\n","\n","#calling the plot functions\n","animated_temp_map()\n","yearly_temp_map(2017)\n","countries_temp_anomaly(2017)\n","co2_emissions(2021)\n","countries_share_piechart(2021)\n","country_co2_emission('China')\n","country_co2_emission('Europe')\n","share_temp(2021)\n","\n","print(\"The countries affected the most by the temperature anomalies are Mongolia, Somalia, Norway, Russia and Afghanistan.\")\n","print(\"However, these are not the countries that have the highest CO2 emissions\")\n","print(\"The countries with the highest emissions are China, US, India, Russia and Japan\")\n","print(\"In China, the emissions are increasing constantly, while in Europe there is a decreasing trend from around 1980.\")"],"metadata":{"id":"CF0_TF6JSLhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgMXTEydw1qM"},"outputs":[],"source":["# lib import\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from tabulate import tabulate\n","%matplotlib inline\n","pd.set_option('display.max_rows', None)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lj6xdJV-H0LD"},"outputs":[],"source":["#load the data\n","df1 = pd.read_csv('/content/owid-co2-data.csv')\n","df2 = pd.read_csv('/content/hadcrut-surface-temperature-anomaly.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uW59vftLHyQA"},"outputs":[],"source":["#merge the datas\n","df2=df2.rename(columns={\"Entity\": \"country\", \"Year\" : \"year\"})\n","merged_df = df1.merge(df2, on=['country', 'year'], how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QZNPOn3gHr5-"},"outputs":[],"source":["#count nan values\n","pd.DataFrame((merged_df.isnull().sum() * 100 / len(merged_df)).round(3)).style.background_gradient(cmap='coolwarm').set_precision(3)\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Calculate the percentage of missing values in each column\n","missing_percentage = (merged_df.isnull().sum() * 100 / len(merged_df)).round(3)\n","\n","# Create a DataFrame with the missing percentages\n","missing_table = pd.DataFrame(missing_percentage, columns=['Missing Percentage'])\n","\n","# Apply background color gradient\n","table_style = missing_table.style.background_gradient(cmap='coolwarm')\n","\n","# Set precision for the displayed percentages\n","table_style.set_precision(3)\n","\n","# Display the table with color-coded missing percentage\n","plt.figure(figsize=(8, 6))\n","plt.axis('off')\n","plt.table(cellText=missing_table.values,\n","          colLabels=missing_table.columns,\n","          cellLoc='center',\n","          rowLabels=missing_table.index,\n","          loc='center',\n","          cellColours=plt.cm.coolwarm(missing_table / 100),\n","          colColours=plt.cm.coolwarm(missing_table / 100))\n","\n","\n","# Save the table as an image\n","plt.savefig('missing_data_table.png', bbox_inches='tight')\n","\n","# Display the table on the screen\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKWZ8CxtIJDZ"},"outputs":[],"source":["#info of datas\n","merged_df.info()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr4uOnZNIYva"},"outputs":[],"source":["#stats of data\n","merged_df.describe().style.background_gradient(cmap='coolwarm').set_precision(3)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VCVb-JNaIdC0"},"outputs":[],"source":["\n","select_cols = ['year','gdp',\"population\", \"co2\", \"coal_co2\", \"gas_co2\", \"methane\", \"nitrous_oxide\", \"total_ghg\", \"oil_co2\", 'Surface temperature anomaly']\n","merged_df[select_cols].describe().style.background_gradient(cmap='coolwarm').set_precision(3)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ut7luMi5Iot5"},"outputs":[],"source":["#CORRELATION\n","merged_df.corr().style.background_gradient(cmap='coolwarm').set_precision(3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_793ktTIxlf"},"outputs":[],"source":["#heatMapCleanedData\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","df = pd.read_csv('./datasets/datas_pre_processed.csv')\n","df.reset_index(drop=True, inplace=True)\n","correlation_matrix = df.corr()\n","correlation_matrix\n","plt.figure(figsize=(16, 14))\n","\n","\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n","\n","plt.title('Correlation Heatmap')\n","plt.show()\n","\n","#Conclusion: surface temperature anomaly seems to have the strongest correlation with year variable. Intensity of the color indicates the low dependence With other variables. However with variables like flaring_co2, gas_co2, gdp, population,coal_co2, co2 correlation is stronger than with land_use_change_co2, trade_co2, oil_co2."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ym_eGSC_Zh33"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","df = pd.read_csv('/content/datas_pre_processed.csv')\n","\n","\n","\n","# Pivot the DataFrame to have 'year' as index, 'country' as columns, and 'surface temperature anomaly' as values\n","heatmap_data = df.pivot(index='year', columns='country', values='surface temperature anomaly')\n","\n","# Create the heatmap using seaborn\n","plt.figure(figsize=(20, 22))\n","sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', linewidths=0.5)\n","plt.title('Surface Temperature Anomaly Heatmap')\n","plt.xlabel('Country')\n","plt.ylabel('Year')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZRvXKw9NatU"},"outputs":[],"source":["#Basic statistics Values\n","import matplotlib\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","df = pd.read_csv('/content/owid-co2-data.csv')\n","print(df.head())\n","\n","\n","\n","# Calculate Mean\n","mean_population = df['population'].mean()\n","mean_gdp = df['gdp'].mean()\n","mean_co2_emissions = df['co2'].mean()\n","\n","# Calculate Median\n","median_co2_per_capita = df['co2_per_capita'].median()\n","median_temperature_change_from_co2 = df['temperature_change_from_co2'].median()\n","\n","\n","\n","# Calculate Range\n","range_co2_emissions = df['co2'].max() - df['co2'].min()\n","range_gdp = df['gdp'].max() - df['gdp'].min()\n","\n","# Calculate Variance and Standard Deviation\n","variance_co2_per_capita = df['co2_per_capita'].var()\n","std_dev_co2_emissions = df['co2'].std()\n","\n","# Calculate Percentiles\n","percentile_25_co2_emissions = df['co2'].quantile(0.25)\n","percentile_75_gdp = df['gdp'].quantile(0.75)\n","\n","# Calculate Correlation\n","correlation_co2_gdp = df['co2'].corr(df['gdp'])\n","\n","# Display the results\n","print(\"Mean Population:\", mean_population)\n","print(\"Mean GDP:\", mean_gdp)\n","print(\"Mean CO2 Emissions:\", mean_co2_emissions)\n","print(\"Median CO2 Emissions per Capita:\", median_co2_per_capita)\n","print(\"Median Temperature Change from CO2:\", median_temperature_change_from_co2)\n","print(\"Range of CO2 Emissions:\", range_co2_emissions)\n","print(\"Range of GDP:\", range_gdp)\n","print(\"Variance of CO2 Emissions per Capita:\", variance_co2_per_capita)\n","print(\"Standard Deviation of CO2 Emissions:\", std_dev_co2_emissions)\n","print(\"25th Percentile of CO2 Emissions:\", percentile_25_co2_emissions)\n","print(\"75th Percentile of GDP:\", percentile_75_gdp)\n","print(\"Correlation between CO2 Emissions and GDP:\", correlation_co2_gdp)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8EXza3QRunSE","executionInfo":{"status":"ok","timestamp":1690810957626,"user_tz":-120,"elapsed":323,"user":{"displayName":"Natalia Gostkowska-Lekner","userId":"17222987657571775063"}},"outputId":"15adfee5-c4b0-4c1f-c582-91fccb70d430"},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}],"source":["#Modelistation\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","#!pip install shap\n","\n","# Dataset import\n","data = pd.read_csv('/content/datas_pre_processed.csv')\n","\n","#drop NaN values\n","data.dropna(inplace=True)\n","print(data.isna().sum().sum())\n","\n","# Separate the features (X) and target (y)\n","X = data[['country', 'code', 'year', 'cement_co2', 'co2', 'coal_co2', 'consumption_co2',\n","          'cumulative_co2', 'flaring_co2', 'gas_co2', 'land_use_change_co2', 'oil_co2',\n","          'trade_co2', 'temperature_change_from_ghg', 'total_ghg', 'gdp', 'population']]\n","y = data['surface temperature anomaly']\n","\n","# Perform one-hot encoding using pandas get_dummies\n","X_encoded = pd.get_dummies(X, columns=['country', 'code'], drop_first=True)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","source":["# Model 1: Gradient Boosting\n","gb_model = GradientBoostingRegressor()\n","gb_model.fit(X_train, y_train)\n","gb_predictions = gb_model.predict(X_test)\n","\n","plt.scatter(y_test, gb_predictions)\n","plt.xlabel(\"Actual Surface Temperature Anomaly\")\n","plt.ylabel(\"Predicted Surface Temperature Anomaly\")\n","plt.title(\"Gradient Boosting: Actual vs. Predicted\")\n","plt.show()\n","\n","#residual plot shows the difference between the actual target values and the predicted values\n","residuals = y_test - gb_predictions\n","plt.hist(residuals, bins=30)\n","plt.xlabel(\"Residuals\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Gradient Boosting: Histogram of Residuals\")\n","plt.show()\n","\n","# Sort feature importances in descending order\n","plt.figure(figsize=(18, 6))\n","plt.bar(range(len(feature_importances)), feature_importances)\n","plt.xticks(range(len(feature_importances)), feature_names, rotation=45, ha='right')\n","plt.xlabel(\"Features\")\n","plt.ylabel(\"Feature Importance\")\n","plt.title(\"Gradient Boosting: Feature Importances\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"usZH5fV_uwe8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shap\n","\n","# Instantiate a SHAP explorer with your model\n","explainer = shap.Explainer(gb_model)\n","\n","# Calculate SHAP values ​​for your training data\n","shap_values = explainer.shap_values(X_train)\n","\n","# Calculate SHAP values ​​for all training data\n","shap_values = explainer.shap_values(X_train)\n","\n","# features importances\n","shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n","\n","# View feature explanations for all workout data\n","shap.summary_plot(shap_values, X_train, feature_names=X_train.columns)\n","\n","# dependency diagram\n","for features in X_train.columns[:-89]:\n","    shap.dependence_plot(features, shap_values, X_train)"],"metadata":{"id":"a3YP0PGRuwsj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Gradient Boosting Regressor scores\n","\n","print('The score for the train set in Gradient Boosting Regressor model is', gb_model.score(X_train, y_train))\n","print('The score for the test set in Gradient Boosting Regressor model is',gb_model.score(X_test, y_test))\n","\n","gb_mae = mean_absolute_error(y_test, gb_predictions)\n","gb_mse = mean_squared_error(y_test, gb_predictions)\n","gb_r2 = r2_score(y_test, gb_predictions)\n","\n","print(\"Gradient Boosting: MAE =\", gb_mae, \"MSE =\", gb_mse, \"R2 =\", gb_r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyQEXp1Kuwzz","executionInfo":{"status":"ok","timestamp":1690806756643,"user_tz":-120,"elapsed":276,"user":{"displayName":"Natalia Gostkowska-Lekner","userId":"17222987657571775063"}},"outputId":"bc8897bf-a990-402a-887b-3ed37addc8c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The score for the train set in Gradient Boosting Regressor model is 0.6685436798838547\n","The score for the test set in Gradient Boosting Regressor model is 0.47795422494520334\n","Gradient Boosting: MAE = 0.36886456051619426 MSE = 0.20860579578025282 R2 = 0.47795422494520334\n"]}]},{"cell_type":"code","source":["# Model 2: Linear Regression\n","lr_model = LinearRegression()\n","lr_model.fit(X_train, y_train)\n","lr_predictions = lr_model.predict(X_test)\n","import matplotlib.pyplot as plt\n","\n","#scatter plot compares the actual target values (y_test) with the predicted values (lr_predictions). It give you a visual sense of how closely the predictions align with the true values.\n","plt.scatter(y_test, lr_predictions)\n","plt.xlabel(\"Actual Surface Temperature Anomaly\")\n","plt.ylabel(\"Predicted Surface Temperature Anomaly\")\n","plt.title(\"Linear Regression: Actual vs. Predicted\")\n","plt.show()\n","\n","#residual plot shows the difference between the actual target values and the predicted values\n","residuals = y_test - lr_predictions\n","plt.hist(residuals, bins=30)\n","plt.xlabel(\"Residuals\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Linear Regression: Histogram of Residuals\")\n","plt.show()\n","\n","#coefficient regression\n","coef_df = pd.DataFrame({'feature': X_encoded.columns, 'coefficient': lr_model.coef_})\n","plt.figure(figsize=(18, 6))\n","plt.bar(coef_df['feature'], coef_df['coefficient'])\n","plt.xticks(rotation=90)\n","plt.xlabel(\"Features\")\n","plt.ylabel(\"Coefficient Value\")\n","plt.title(\"Linear Regression: Coefficients\")\n","plt.show()\n"],"metadata":{"id":"DGl40UJBxI44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Linear Regression model scores\n","\n","print('The score for the train set in Linear Regression model is', lr_model.score(X_train, y_train))\n","print('The score for the test set in Linear Regression model is',lr_model.score(X_test, y_test))\n","lr_mae = mean_absolute_error(y_test, lr_predictions)\n","lr_mse = mean_squared_error(y_test, lr_predictions)\n","lr_r2 = r2_score(y_test, lr_predictions)\n","\n","print(\"Linear Regression: MAE =\", lr_mae, \"MSE =\", lr_mse, \"R2 =\", lr_r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ymwnKphxJIe","executionInfo":{"status":"ok","timestamp":1690805386598,"user_tz":-120,"elapsed":10,"user":{"displayName":"Natalia Gostkowska-Lekner","userId":"17222987657571775063"}},"outputId":"eb92528f-5257-4b47-af45-0f9a9545b8d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The score for the train set in Linear Regression model is 0.3830772042758873\n","The score for the test set in Linear Regression model is 0.2966630838026795\n","Linear Regression: MAE = 0.42701363077605214 MSE = 0.2810484522924652 R2 = 0.2966630838026795\n"]}]},{"cell_type":"code","source":["#Model 3, Decision Tree Regressor, Natalia\n","\n","from sklearn.tree import DecisionTreeRegressor\n","regressor = DecisionTreeRegressor(random_state=42)\n","regressor.fit(X_train, y_train)\n","y_pred = regressor.predict(X_test)"],"metadata":{"id":"R72CWG7ex4ge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.scatter(y_test, y_pred)\n","plt.xlabel(\"True value (y_test)\")\n","plt.ylabel(\"Prediction (y_pred)\")\n","plt.title(\"Check for Overfitting/Underfitting in Decision Tree Regressor model\")\n","plt.show()\n","\n","#residual plot shows the difference between the actual target values and the predicted values\n","residuals = y_test - y_pred\n","plt.hist(residuals, bins=30)\n","plt.xlabel(\"Residuals\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Decision Tree Regressor: Histogram of Residuals\")\n","plt.show()\n","\n","feature_importance = regressor.feature_importances_\n","plt.figure(figsize=(18, 6))\n","plt.bar(X_encoded.columns[:15], feature_importance[:15])\n","plt.xlabel(\"Features\")\n","plt.ylabel(\"Importance\")\n","plt.title(\"Features Importance Decision Tree Regressor\")\n","plt.xticks(rotation=90)\n","plt.show()\n"],"metadata":{"id":"4UqwdWv1x4l-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WAXKiF_PUBvB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instantiate a SHAP explorer with  model\n","explainer = shap.Explainer(regressor)\n","\n","# Calculate SHAP values ​​for  training data\n","shap_values = explainer.shap_values(X_train)\n","\n","# Calculate SHAP values ​​for all training data\n","shap_values = explainer.shap_values(X_train)\n","\n","# features importances\n","shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n","\n","# View feature explanations for all workout data\n","shap.summary_plot(shap_values, X_train, feature_names=X_train.columns)\n","\n","# dependency diagram\n","for features in X_train.columns[:-89]:\n","    shap.dependence_plot(features, shap_values, X_train)"],"metadata":{"id":"m_ruNE5xx4or"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('The score for the train set in Decision Tree Regressor model is', regressor.score(X_train, y_train))\n","print('The score for the test set in Decision Tree Regressor model is',regressor.score(X_test, y_test))\n","\n","rmse_dtr = mean_squared_error(y_test, y_pred, squared=False)\n","regressor_mae = mean_absolute_error(y_test, y_pred)\n","regressor_mse = mean_squared_error(y_test, y_pred)\n","regressor_r2 = r2_score(y_test, y_pred)\n","\n","print(\"Decision Tree Regressor: MAE =\", regressor_mae, \"MSE =\", regressor_mse, \"R2 =\", regressor_r2)\n","print('The mean squared error for Decision Tree Regressor model is', rmse_dtr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XeF28MdBx4ro","executionInfo":{"status":"ok","timestamp":1690805424593,"user_tz":-120,"elapsed":299,"user":{"displayName":"Natalia Gostkowska-Lekner","userId":"17222987657571775063"}},"outputId":"78b475d2-7e7e-4f62-bfe4-178855b44a55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The score for the train set in Decision Tree Regressor model is 1.0\n","The score for the test set in Decision Tree Regressor model is 0.1449729358152837\n","Decision Tree Regressor: MAE = 0.4771548117154812 MSE = 0.3416627615062761 R2 = 0.1449729358152837\n","The mean squared error for Decision Tree Regressor model is 0.5845192567454696\n"]}]},{"cell_type":"code","source":["#Model 4, Random Forest Regressor, Natalia\n","\n","from sklearn.ensemble import RandomForestRegressor\n","model = RandomForestRegressor(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","y_pred_rfr = model.predict(X_test)\n","\n"],"metadata":{"id":"n3XsETPVy9_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","plt.scatter(y_test, y_pred_rfr)\n","plt.xlabel(\"True value (y_test)\")\n","plt.ylabel(\"Prediction (y_pred)\")\n","plt.title(\"Check for Overfitting/Underfitting in Random Forest Regressor model\")\n","plt.show()\n","\n","#residual plot shows the difference between the actual target values and the predicted values\n","residuals = y_test - y_pred_rfr\n","plt.hist(residuals, bins=30)\n","plt.xlabel(\"Residuals\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Random Forest Regressor: Histogram of Residuals\")\n","plt.show()\n","\n","feature_importance = model.feature_importances_\n","plt.figure(figsize=(18, 6))\n","plt.bar(X_encoded.columns[:15], feature_importance[:15])\n","plt.xlabel(\"Features\")\n","plt.ylabel(\"Importance\")\n","plt.title(\"Features Importance Random Forest Regressor\")\n","plt.xticks(rotation=90)\n","plt.show()"],"metadata":{"id":"a6JLvM6MzJ7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instantiate a SHAP explorer with  model\n","explainer = shap.Explainer(model)\n","\n","# Calculate SHAP values ​​for  training data\n","shap_values = explainer.shap_values(X_train)\n","\n","# Calculate SHAP values ​​for all training data\n","shap_values = explainer.shap_values(X_train)\n","\n","# features importances\n","shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n","\n","# View feature explanations for all workout data\n","shap.summary_plot(shap_values, X_train, feature_names=X_train.columns)\n","\n","# dependency diagram\n","for features in X_train.columns[:-89]:\n","    shap.dependence_plot(features, shap_values, X_train)"],"metadata":{"id":"8OGQ9Yi81wh7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print('The score for the train set in Random Forest Regressor model is', model.score(X_train, y_train))\n","print('The score for the test set in Random Forest Regressor model is', model.score(X_test, y_test))\n","\n","\n","rmse_rfr = mean_squared_error(y_test, y_pred_rfr, squared=False)\n","rfr_mae = mean_absolute_error(y_test, y_pred_rfr)\n","rfr_mse = mean_squared_error(y_test, y_pred_rfr)\n","rfr_r2 = r2_score(y_test, y_pred_rfr)\n","\n","print(\"Random Forest Regressor: MAE =\", rfr_mae, \"MSE =\", rfr_mse, \"R2 =\", rfr_r2)\n","print('The mean squared error for Random Forest Regressor model is', rmse_rfr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBph5e8xy-C1","executionInfo":{"status":"ok","timestamp":1690805672444,"user_tz":-120,"elapsed":418,"user":{"displayName":"Natalia Gostkowska-Lekner","userId":"17222987657571775063"}},"outputId":"5f62625a-cbae-4123-a44d-663d7b228b77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The score for the train set in Random Forest Regressor model is 0.9192371003443776\n","The score for the test set in Random Forest Regressor model is 0.45153963992793\n","Decision Tree Regressor: MAE = 0.3865979079497908 MSE = 0.21916087694560674 R2 = 0.45153963992793\n","The mean squared error for Decision Tree Regressor model is 0.46814621321293065\n"]}]},{"cell_type":"markdown","source":["# Nowa sekcja"],"metadata":{"id":"UvJbZQIhRg-k"}}]}