{"cells":[{"cell_type":"markdown","metadata":{"id":"3tTZPEVzIQwJ"},"source":["# 3. Data preprocessing\n"," 3.1 Data cleansing\n"," 3.2 Data reduction\n"," 3.3 Data transformation\n"," 3.4 Data enrichment\n"," 3.5 Data validation"]},{"cell_type":"markdown","metadata":{"id":"Sz7wyeFBIQwW"},"source":["#### Import modules and data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J31HFAQ9IQwZ"},"outputs":[],"source":["%config Completer.use_jedi = False\n","\n","from sklearn.preprocessing import StandardScaler    # Machine Learning\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import FactorAnalysis\n","from sklearn.linear_model import LinearRegression\n","from sklearn import preprocessing, svm\n","import statistics\n","import statsmodels.api as sm\n","import plotly.express as px    # Creates entire figures\n","import seaborn as sns   # Data visuals\n","import matplotlib.pyplot as plt  # Plots\n","import numpy as np      # Working with arrays and math\n","import pandas as pd     # For data analiysis and data process\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","# Read the two datasets into DataFrames\n","df_hadcrut = pd.read_csv('./datasets/hadcrut-surface-temperature-anomaly.csv')\n","df_co2 = pd.read_csv('./datasets/owid-co2-data.csv')\n","print(\"Hadcrut-data consists of:\", df_hadcrut.shape[0],\"rows\")\n","print(\"Owid-co2-data consists of:\", df_co2.shape[0],\"rows\")"]},{"cell_type":"markdown","metadata":{"id":"6saGyn5SIQwd"},"source":["#### 3.1 Cleaning Process: HADCRUT-SURFACE-TEMPERATURE-ANOMALY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5__EwunIQwf"},"outputs":[],"source":["## Rename columns\n","df_hadcrut = df_hadcrut.rename(columns=str.lower)\n","df_hadcrut = df_hadcrut.rename(columns={'entity': 'country'})\n","df_hadcrut = df_hadcrut.rename(columns={'code': 'iso_code'})\n","## Check NaN-rate for columns\n","def nan_rate (selected_column):\n","    nan_rate = df_hadcrut[selected_column].isna().mean()\n","    print(f\"NaN-Rate der Spalte '{selected_column}': {nan_rate:.2%}\")\n","nan_rate ('country')\n","nan_rate ('iso_code')\n","nan_rate ('year')\n","nan_rate ('surface temperature anomaly')\n","#print(df_hadcrut.isnull().sum())\n","df_hadcrut.loc[df_hadcrut['country'] == 'Micronesia', 'iso_code'] = 'FSM'\n","## If a NaN value or duplicate is found, delete the line\n","df_hadcrut.dropna(inplace=True)\n","df_hadcrut.drop_duplicates(inplace=True)\n","row1 = df_hadcrut.shape[0]\n","## Identify outliers with a boxplot\n","plt.boxplot(df_hadcrut['surface temperature anomaly'])\n","plt.ylabel('Surface Temperature Anomaly')\n","plt.xlabel('Boxplot')\n","plt.title('Identify outliers ')\n","plt.show()\n","# Delete outliners with the Z-score method:\n","z_scores = np.abs((df_hadcrut['surface temperature anomaly'] - df_hadcrut['surface temperature anomaly'].mean()) / df_hadcrut['surface temperature anomaly'].std())\n","# Define a limit above which a value is considered an outlier (Z-score > 3)\n","threshold = 3\n","# Entferne die Zeilen, die den Schwellenwert Ã¼berschreiten\n","df_hadcrut = df_hadcrut[z_scores <= threshold]\n","row2 = df_hadcrut.shape[0]\n","print(\"Deleted rows:\", row1 - row2)\n","print(\"Hadcrut-data consists of:\", df_hadcrut.shape[0],\"rows\")"]},{"cell_type":"markdown","metadata":{"id":"H4T2xPpUIQwl"},"source":["#### 3.1 Cleaning Process: OWDI-CO2-DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nL8oIBd-IQwn"},"outputs":[],"source":["# If a NaN value or duplicate is found, delete the line\n","row1 = df_co2.shape[0]\n","df_co2.dropna(inplace=True)\n","df_co2.drop_duplicates(inplace=True)\n","# Delete from the 'country' column all substrings which are in brackets\n","df_co2['country'] = df_co2['country'].str.replace(r'\\s*\\(.*\\)', '')\n","row2 = df_co2.shape[0]\n","print(\"Deleted rows:\", row1 - row2)\n","print(\"Owid-co2-data consists of:\", df_co2.shape[0],\"rows\")"]},{"cell_type":"markdown","metadata":{"id":"WPiE_wICIQwp"},"source":["#### Merge Owid-co2 and Hadcrut"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0_NdKo3IQwr"},"outputs":[],"source":["# Merge the two DataFrames on the country and year and iso_code columns\n","# the 'iso_code' field is important so that no 'non-countries' are selected from owid-co2\n","df = df_hadcrut.merge(df_co2, on=['country', 'iso_code', 'year'])\n","# Identify the target variable, which is the anomaly temperature\n","target = 'surface temperature anomaly'\n","# Select a maximum of 15 columns from the merged DataFrame, including the target variable\n","selected_columns = ['country', 'iso_code', 'year'] + [target] + list(df.filter(like='co2')[:15]) + list(df.filter(like='ghg')[:1]) + ['nitrous_oxide', 'methane', 'gdp', 'population']\n","# Create a new DataFrame with the selected columns\n","df_pre_processed = df[selected_columns]\n","# Delete unnecessary columns\n","to_drop = ['cement_co2_per_capita',\n","           'co2_including_luc',\n","           'co2_including_luc_growth_abs',\n","           'co2_including_luc_growth_prct',\n","           'co2_including_luc_per_capita',\n","           'co2_including_luc_per_gdp',\n","           'share_global_cement_co2',\n","           'share_global_co2',\n","           'share_global_co2_including_luc',\n","           'share_global_coal_co2',\n","           'share_global_cumulative_cement_co2',\n","           'share_global_cumulative_co2',\n","           'share_global_cumulative_co2_including_luc',\n","           'share_global_cumulative_coal_co2',\n","           'share_global_cumulative_gas_co2',\n","           'share_global_cumulative_luc_co2',\n","           'share_global_cumulative_oil_co2',\n","           'share_global_cumulative_other_co2',\n","           'share_global_flaring_co2',\n","           'share_global_gas_co2',\n","           'share_global_luc_co2',\n","           'share_global_oil_co2',\n","           'share_global_other_co2',\n","           'co2_including_luc_per_unit_energy',\n","           'co2_per_capita',\n","           'co2_per_gdp',\n","           'co2_per_unit_energy',\n","           'coal_co2_per_capita',\n","           'consumption_co2_per_capita',\n","           'consumption_co2_per_gdp',\n","           'cumulative_cement_co2',\n","           'cumulative_co2_including_luc',\n","           'cumulative_coal_co2',\n","           'cumulative_flaring_co2',\n","           'cumulative_gas_co2',\n","           'cumulative_luc_co2',\n","           'cumulative_oil_co2',\n","           'cumulative_other_co2',\n","           'flaring_co2_per_capita',\n","           'gas_co2_per_capita',\n","           'land_use_change_co2_per_capita',\n","           'oil_co2_per_capita',\n","           'other_co2_per_capita',\n","           'other_industry_co2',\n","           'share_global_cumulative_flaring_co2',\n","           'temperature_change_from_co2',\n","           'trade_co2_share',\n","           'ghg_excluding_lucf_per_capita',\n","           'ghg_per_capita',\n","           'share_of_temperature_change_from_ghg',\n","           'iso_code',\n","           'total_ghg',\n","           'total_ghg_excluding_lucf',\n","           'temperature_change_from_ghg',\n","           'cement_co2',\n","           'co2_growth_abs',\n","           'co2_growth_prct',\n","           'consumption_co2',\n","           'cumulative_co2',\n","           'land_use_change_co2',\n","           'trade_co2']\n","df_pre_processed.drop(to_drop, inplace=True, axis=1)\n","# Sort df_analyse\n","desired_order = ['country', 'year', 'gdp', 'population', 'co2', 'coal_co2', 'flaring_co2',\n","                 'gas_co2', 'methane', 'nitrous_oxide', 'oil_co2', 'surface temperature anomaly']\n","df_pre_processed = df_pre_processed[desired_order]\n","# Rename 'surface temperature anomaly' to sta\n","df_pre_processed.rename(\n","    columns={'surface temperature anomaly': 'sta'}, inplace=True)\n","# Check for duplicates\n","df_pre_processed.drop_duplicates()\n","# Convert the object column 'country' to a numeric column 'country_id'\n","df_pre_processed['country_id'] = pd.factorize(df_pre_processed['country'])[0]\n","# Create a new dataframe 'df_country', which contains the assignment 'country_id' and 'country'\n","df_country = df_pre_processed[['country', 'country_id']].copy()\n","df_country.drop_duplicates(inplace=True)\n","# Move the column 'country_id' to the first position\n","column_order = ['country_id'] + \\\n","    [col for col in df_pre_processed.columns if col != 'country_id']\n","df_pre_processed = df_pre_processed.reindex(columns=column_order)\n","# Set country_id and year as index\n","#df_pre_processed.set_index(['country_id', 'year'], inplace=True)\n","# Delete column 'country' so that the dataframe contains only numeric values\n","df_pre_processed.drop('country', axis=1, inplace=True)\n","# Save the new DataFrame as a CSV file\n","df_pre_processed.to_csv('./datasets/datas_pre_processed.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pagrwtZMIQwv"},"outputs":[],"source":["'''target_variable = df['sta']\n","features = df.drop('sta', axis=1)\n","\n","# Min-Max-Normalisierung der Features\n","normalized_features = (features - features.min()) / (features.max() - features.min())\n","'''"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}